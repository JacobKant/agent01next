- Добавьте в код подсчёт токенов (на запрос и ответ)
- Сравните: короткий запрос, длинный запрос и запрос, превышающий лимит модели

Выводы
При длинных запросах модель не помнит начала диалога если он не влезает в контекст, 
зависит от провайдера и модели, может  быть context length exceeded ошибка 500, либо автоматическое усечение запроса

При жестком ограничении выходных токенов ответ обрезается